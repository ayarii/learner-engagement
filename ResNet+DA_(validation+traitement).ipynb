{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayarii/learner-engagement/blob/main/ResNet%2BDA_(validation%2Btraitement).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P0FFga0fefUj"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import sys\n",
        "import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
        "from tensorflow.keras import layers, callbacks\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Import dataset\n",
        "data_dir = tf.keras.utils.get_file(\n",
        "    \"dataset.zip\",\n",
        "    \"https://github.com/ayarii/learner-engagement/blob/main/Student-engagement-dataset.zip?raw=true\",\n",
        "    extract=False)\n",
        "with zipfile.ZipFile(data_dir, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/datasets')\n",
        "data_dir = pathlib.Path('/content/datasets/Student-engagement-dataset')\n",
        "print(data_dir)\n",
        "print(os.path.abspath(data_dir))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2inyj7UlaDz",
        "outputId": "17d1cb89-724c-4460-d98a-ef49ecb0222d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/datasets/Student-engagement-dataset\n",
            "/content/datasets/Student-engagement-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Chemin vers le dossier contenant vos dossiers d'ensemble de données\n",
        "data_dir = '/content/datasets/Student-engagement-dataset'\n",
        "\n",
        "# Chemin vers le dossier où vous souhaitez placer les ensembles de traitement et de validation\n",
        "output_dir = '/content/datasets'\n",
        "\n",
        "# Liste des noms de dossiers dans votre ensemble de données\n",
        "folder_names = os.listdir(data_dir)\n",
        "\n",
        "# Création des dossiers de traitement et de validation s'ils n'existent pas déjà\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "val_dir = os.path.join(output_dir, 'validation')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "# Répartition des données en ensembles de traitement et de validation\n",
        "for folder_name in folder_names:\n",
        "    folder_path = os.path.join(data_dir, folder_name)\n",
        "    images = os.listdir(folder_path)\n",
        "    train_images, val_images = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Création des sous-dossiers dans les ensembles de traitement et de validation\n",
        "    train_folder_path = os.path.join(train_dir, folder_name)\n",
        "    val_folder_path = os.path.join(val_dir, folder_name)\n",
        "    os.makedirs(train_folder_path, exist_ok=True)\n",
        "    os.makedirs(val_folder_path, exist_ok=True)\n",
        "\n",
        "    # Déplacement des images dans les sous-dossiers correspondants\n",
        "    for image in train_images:\n",
        "        shutil.copy(os.path.join(folder_path, image), os.path.join(train_folder_path, image))\n",
        "    for image in val_images:\n",
        "        shutil.copy(os.path.join(folder_path, image), os.path.join(val_folder_path, image))\n",
        "\n",
        "print(\"Données divisées en ensembles de traitement et de validation avec succès.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4u-fb0d1CbA",
        "outputId": "39260e22-12ab-4812-a445-492f93687aac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Données divisées en ensembles de traitement et de validation avec succès.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chemin vers les dossiers d'entraînement et de validation\n",
        "train_dir = '/content/datasets/train/'\n",
        "val_dir = '/content/datasets/validation/'\n",
        "\n",
        "# Fonction pour compter le nombre total d'images dans un dossier\n",
        "def count_images_in_directory(directory):\n",
        "    total_images = 0\n",
        "    # Parcours de chaque sous-dossier dans le répertoire\n",
        "    for sub_directory in os.listdir(directory):\n",
        "        sub_directory_path = os.path.join(directory, sub_directory)\n",
        "        # Comptage des fichiers dans le sous-dossier\n",
        "        if os.path.isdir(sub_directory_path):\n",
        "            num_images = len([filename for filename in os.listdir(sub_directory_path)\n",
        "                              if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg')])\n",
        "            total_images += num_images\n",
        "    return total_images\n",
        "\n",
        "# Comptage du nombre total d'images dans chaque dossier\n",
        "total_train_images = count_images_in_directory(train_dir)\n",
        "total_val_images = count_images_in_directory(val_dir)\n",
        "\n",
        "# Affichage du nombre total d'images dans chaque dossier\n",
        "print(\"Nombre total d'images dans le dossier d'entraînement :\", total_train_images)\n",
        "print(\"Nombre total d'images dans le dossier de validation :\", total_val_images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8FJvkBN1XmG",
        "outputId": "cb69275a-a7db-470d-8615-18fdb9fb6f8d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre total d'images dans le dossier d'entraînement : 1694\n",
            "Nombre total d'images dans le dossier de validation : 426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Chemin vers le dossier contenant vos dossiers d'ensemble de données\n",
        "data_dir = '/content/datasets/Student-engagement-dataset'\n",
        "\n",
        "# Chemin vers le dossier où vous souhaitez placer les ensembles de traitement et de validation\n",
        "output_dir = '/content/datasets'\n",
        "\n",
        "# Liste des noms de dossiers dans votre ensemble de données\n",
        "folder_names = os.listdir(data_dir)\n",
        "\n",
        "# Création des dossiers de traitement et de validation s'ils n'existent pas déjà\n",
        "train_dir = os.path.join(output_dir, 'train')\n",
        "val_dir = os.path.join(output_dir, 'validation')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "# Répartition des données en ensembles de traitement et de validation\n",
        "for folder_name in folder_names:\n",
        "    folder_path = os.path.join(data_dir, folder_name)\n",
        "    images = os.listdir(folder_path)\n",
        "    train_images, val_images = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Création des sous-dossiers dans les ensembles de traitement et de validation\n",
        "    train_folder_path = os.path.join(train_dir, folder_name)\n",
        "    val_folder_path = os.path.join(val_dir, folder_name)\n",
        "    os.makedirs(train_folder_path, exist_ok=True)\n",
        "    os.makedirs(val_folder_path, exist_ok=True)\n",
        "\n",
        "    # Déplacement des images dans les sous-dossiers correspondants\n",
        "    for image in train_images:\n",
        "        shutil.copy(os.path.join(folder_path, image), os.path.join(train_folder_path, image))\n",
        "    for image in val_images:\n",
        "        shutil.copy(os.path.join(folder_path, image), os.path.join(val_folder_path, image))\n",
        "\n",
        "print(\"Données divisées en ensembles de traitement et de validation avec succès.\")\n",
        "\n",
        "# Création des générateurs de données pour l'entraînement et la validation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),  # ResNet50 prend des images de taille 224x224\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Chargement du modèle ResNet50 pré-entraîné\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Création du modèle complet en ajoutant des couches supplémentaires au dessus du modèle ResNet50\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(train_generator.class_indices), activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Callbacks TensorBoard et EarlyStopping\n",
        "log_dir = \"logs/\"\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, write_images=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Compilation du modèle\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5), loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "# Entraînement du modèle\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=100,\n",
        "    callbacks=[tensorboard_callback, early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYfrgKSbYwS4",
        "outputId": "8c1dd241-f062-4e3f-c16e-74ed3bbec2f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Données divisées en ensembles de traitement et de validation avec succès.\n",
            "Found 1694 images belonging to 6 classes.\n",
            "Found 426 images belonging to 6 classes.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               51380736  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 3078      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 74971526 (285.99 MB)\n",
            "Trainable params: 74918406 (285.79 MB)\n",
            "Non-trainable params: 53120 (207.50 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "53/53 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.8878"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Création d'un générateur de données pour l'augmentation des images\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "# Sélection d'une image à augmenter\n",
        "example_image_path = os.path.join(train_dir, folder_names[0], os.listdir(os.path.join(train_dir, folder_names[0]))[0])\n",
        "\n",
        "# Charger l'image\n",
        "img = load_img(example_image_path)\n",
        "x = img_to_array(img)\n",
        "x = x.reshape((1,) + x.shape)  # Transforme en un tableau de forme (1, img_height, img_width, img_channels)\n",
        "\n",
        "# Génération et affichage de 10 images augmentées\n",
        "fig, axs = plt.subplots(2, 5, figsize=(15, 6))\n",
        "for i, batch in enumerate(datagen.flow(x, batch_size=1)):\n",
        "    axs[i // 5, i % 5].imshow(array_to_img(batch[0]))\n",
        "    axs[i // 5, i % 5].axis('off')\n",
        "    if i == 9:  # Change 9 to the desired number of images minus 1\n",
        "        break\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1QqoUcIAr3TK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(val_generator, verbose=0)\n",
        "print(f'vall loss: {loss:.4f}')\n",
        "print(f'vall accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "id": "kl4tFRnZS-X3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dTEswXCQXXo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"loss\",\"Validation loss\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JHZg72TPZW1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Utilisez le modèle pour prédire les classes sur les données de validation\n",
        "y_pred = model.predict(val_generator)\n",
        "y_true = val_generator.classes\n",
        "\n",
        "# Convertissez les probabilités prédites en classes prédites (classe avec la probabilité la plus élevée)\n",
        "y_pred_classes = y_pred.argmax(axis=-1)\n",
        "\n",
        "# Calcul des métriques de classification\n",
        "report = classification_report(y_true, y_pred_classes, target_names=val_generator.class_indices, output_dict=True)\n",
        "\n",
        "# Affichage des métriques pour chaque classe\n",
        "for class_name, metrics in report.items():\n",
        "    print(f'Classe : {class_name}')\n",
        "    print(f'   Précision : {metrics[\"precision\"]}')\n",
        "    print(f'   Rappel : {metrics[\"recall\"]}')\n",
        "    print(f'   Score F1 : {metrics[\"f1-score\"]}')\n",
        "    print(f'   Support : {metrics[\"support\"]}\\n')\n"
      ],
      "metadata": {
        "id": "lttUulloZdK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# la matrice de confusion\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculer la matrice de confusion\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "# Créer un heatmap de la matrice de confusion\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', xticklabels=val_generator.class_indices.keys(), yticklabels=val_generator.class_indices.keys())\n",
        "plt.xlabel('Classe Prédite')\n",
        "plt.ylabel('Classe Réelle')\n",
        "plt.title('Matrice de Confusion')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MoY-0KnnWfHA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}